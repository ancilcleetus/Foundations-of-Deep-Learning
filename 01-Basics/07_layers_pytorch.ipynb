{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Layers in PyTorch"
      ],
      "metadata": {
        "id": "ejmAF3rR90aI"
      },
      "id": "ejmAF3rR90aI"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "30b88962-f0bf-4aca-92fe-5b02f54f4f7a",
      "metadata": {
        "id": "30b88962-f0bf-4aca-92fe-5b02f54f4f7a"
      },
      "outputs": [],
      "source": [
        "# Basic Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Layer"
      ],
      "metadata": {
        "id": "VBy_Sr_n1MO_"
      },
      "id": "VBy_Sr_n1MO_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Input tensor x has a shape of (batch_size, input_features)\n",
        "    1. batch_size -> no of samples in input batch\n",
        "    2. input_features -> no of features in each sample\n",
        "- Weight matrix has a shape of (output_features, input_features)\n",
        "    1. output_features -> no of neurons in the layer\n",
        "    2. Each row of weight matrix corresponds to weights associated with one neuron in the layer\n",
        "    3. Each column of weight matrix corresponds to weights associated with one input feature\n",
        "- Bias has a shape of (output_features,)\n",
        "    1. One bias value for each neuron in the layer\n",
        "- Output has a shape of (batch_size, output_features)\n",
        "    1. ```outputs = inputs.mm(weights.t()) + bias```"
      ],
      "metadata": {
        "id": "comvLwyk2KNn"
      },
      "id": "comvLwyk2KNn"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "# batch_size = 4, input_features = 3\n",
        "inputs = torch.rand((4, 3))\n",
        "print(f\"inputs = \\n{inputs}\")\n",
        "\n",
        "linear_layer = nn.Linear(in_features=3, out_features=2, bias=True)\n",
        "\n",
        "outputs = linear_layer(inputs)\n",
        "print(f\"outputs = \\n{outputs}\")\n",
        "print(f\"outputs.shape = \\n{outputs.shape}\")"
      ],
      "metadata": {
        "id": "Q8pxYIL1GQFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595b8700-9e48-4a19-eac7-1fa67a12d9e7"
      },
      "id": "Q8pxYIL1GQFf",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs = \n",
            "tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009],\n",
            "        [0.2566, 0.7936, 0.9408],\n",
            "        [0.1332, 0.9346, 0.5936]])\n",
            "outputs = \n",
            "tensor([[0.2849, 0.5152],\n",
            "        [0.3375, 0.2940],\n",
            "        [0.1639, 0.5598],\n",
            "        [0.0256, 0.6029]], grad_fn=<AddmmBackward0>)\n",
            "outputs.shape = \n",
            "torch.Size([4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional Layer"
      ],
      "metadata": {
        "id": "MqDXog5m1btG"
      },
      "id": "MqDXog5m1btG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Output Dimension = [(Input Dimension + 2 * Padding - Kernel Size) / Stride] + 1"
      ],
      "metadata": {
        "id": "8KiwuWfZ1v4Q"
      },
      "id": "8KiwuWfZ1v4Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Layers"
      ],
      "metadata": {
        "id": "fsWBKq9p1SZ3"
      },
      "id": "fsWBKq9p1SZ3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Linear Layer"
      ],
      "metadata": {
        "id": "JMRky9Qu1ggN"
      },
      "id": "JMRky9Qu1ggN"
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLinear(nn.Module):\n",
        "  def __init__(self, in_features, out_features, bias):\n",
        "    super(CustomLinear, self).__init__()\n",
        "\n",
        "    # Define Linear layer parameters\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "    self.bias = bias\n",
        "\n",
        "    # Initialize weights and biases\n",
        "    self.weights = nn.Parameter(torch.randn(self.out_features, self.in_features))\n",
        "    if self.bias:\n",
        "      self.biases = nn.Parameter(torch.randn(self.out_features))\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.bias:\n",
        "      return x.mm(self.weights.t()) + self.biases\n",
        "    else:\n",
        "      return x.mm(self.weights.t())"
      ],
      "metadata": {
        "id": "jTcv_1WUXOu5"
      },
      "id": "jTcv_1WUXOu5",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "# batch_size = 4, input_features = 3\n",
        "inputs = torch.rand((4, 3))\n",
        "print(f\"inputs = \\n{inputs}\")\n",
        "\n",
        "linear_layer = CustomLinear(in_features=3, out_features=2, bias=True)\n",
        "\n",
        "outputs = linear_layer(inputs)\n",
        "print(f\"outputs = \\n{outputs}\")\n",
        "print(f\"outputs.shape = \\n{outputs.shape}\")"
      ],
      "metadata": {
        "id": "u-26Z0t4GVTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17019966-10c7-45ea-c646-60d2b66e29ae"
      },
      "id": "u-26Z0t4GVTe",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs = \n",
            "tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009],\n",
            "        [0.2566, 0.7936, 0.9408],\n",
            "        [0.1332, 0.9346, 0.5936]])\n",
            "outputs = \n",
            "tensor([[ 2.6515, -0.6546],\n",
            "        [ 3.2569, -0.7381],\n",
            "        [ 1.6048, -0.4353],\n",
            "        [ 1.0822, -0.6739]], grad_fn=<AddBackward0>)\n",
            "outputs.shape = \n",
            "torch.Size([4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Conv2D Layer"
      ],
      "metadata": {
        "id": "r5LFZSpv1kXl"
      },
      "id": "r5LFZSpv1kXl"
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomConv2D(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    super(CustomConv2D, self).__init__()\n",
        "\n",
        "    # Define Convolutional layer parameters\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "\n",
        "    # Initialize Convolutional weights and biases\n",
        "    self.weights = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size))\n",
        "    self.bias = nn.Parameter(torch.randn(out_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Get the dimensions of the input tensor\n",
        "      batch_size, in_channels, height, width = x.size()\n",
        "\n",
        "      # Calculate dimensions after applying padding\n",
        "      padded_height = height + (padding * 2)\n",
        "      padded_width = width + (padding * 2)\n",
        "\n",
        "      # Calculate dimensions after applying stride\n",
        "      output_height = (padded_height - self.kernel_size) // self.stride + 1\n",
        "      output_width = (padded_width - self.kernel_size) // self.stride + 1\n",
        "\n",
        "      # Initialize output tensor\n",
        "      output = torch.zeros(batch_size, self.out_channels, output_height, output_width)\n",
        "\n",
        "      # Perform the convolution operation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DW83ZIAY1ndN"
      },
      "id": "DW83ZIAY1ndN",
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}